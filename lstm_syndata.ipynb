{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_syndata.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9UkonThqTOH",
        "outputId": "7f01c0b4-2dd5-4d73-ab4e-11213138da95"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aywn_SiKpl-W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "import string\n",
        "import copy\n",
        "import torch\n",
        "from torch._C import dtype\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Synthetic_Data.csv', dtype={\"text\":\"str\"})\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "kYqyssLUpzmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499821dc-40fb-47b2-a331-de57dda3a052"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['label', 'text', 'predict', 'loss'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop useless columns\n",
        "df.drop(\n",
        "    columns=[\n",
        "        \"predict\",\n",
        "        \"loss\",\n",
        "    ],\n",
        "    inplace=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Zvt8vnvuqgjL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename\n",
        "df.rename(columns={'text':'Text'}, inplace=True)"
      ],
      "metadata": {
        "id": "Fk5e0PXEGBIa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sentiment: 2 = positive, 1 = negative\n",
        "st = []\n",
        "count = 0\n",
        "for l in list(df[\"label\"].values):\n",
        "    if l == 2:\n",
        "        st.append(1)\n",
        "        count += 1\n",
        "    else:\n",
        "        st.append(0)\n",
        "    pass\n",
        "df[\"st\"] = st\n",
        "df.drop(columns=[\"label\"], inplace=True,)"
      ],
      "metadata": {
        "id": "RyT5QrOrFAla"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LCNdKJh8Fbht",
        "outputId": "fbe52102-9937-43da-a95f-2edf165e43fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>st</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So what they are great job , u back to Bar or ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This seems to wonder if \\ '' halo-halo\\ '' ste...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really ? ? ! I have an appt with a cheap , jus...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I called \\ '' hotel is a line ! ! The fish tas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I would have said in on request never experien...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>these words , everything has more restaurants ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>I 've never heard that I think its usually fri...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>This place great music playing music from host...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>This place was great recommendation .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Service stops during a delight ! My kids and s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  st\n",
              "0     So what they are great job , u back to Bar or ...   0\n",
              "1     This seems to wonder if \\ '' halo-halo\\ '' ste...   0\n",
              "2     Really ? ? ! I have an appt with a cheap , jus...   0\n",
              "3     I called \\ '' hotel is a line ! ! The fish tas...   0\n",
              "4     I would have said in on request never experien...   0\n",
              "...                                                 ...  ..\n",
              "9995  these words , everything has more restaurants ...   1\n",
              "9996  I 've never heard that I think its usually fri...   1\n",
              "9997  This place great music playing music from host...   1\n",
              "9998              This place was great recommendation .   1\n",
              "9999  Service stops during a delight ! My kids and s...   1\n",
              "\n",
              "[10000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_len of the reviews\n",
        "max_len = 0\n",
        "for t in list(df[\"Text\"].values):\n",
        "    temp = t.split()\n",
        "    max_len = max(max_len, len(temp))\n",
        "    pass\n",
        "print(\"the max length is:\", max_len)\n",
        "\n",
        "# lower the case, remove the punctuations\n",
        "res = []\n",
        "for t in list(df[\"Text\"].values):\n",
        "    t = t.lower()\n",
        "\n",
        "    for p in punctuation:\n",
        "        t = t.replace(p, \"\")\n",
        "\n",
        "    res.append(t)\n",
        "    pass\n",
        "\n",
        "\n",
        "print(\"review example:\", res[0])\n",
        "df[\"Text\"] = res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDAqB2VpGHwB",
        "outputId": "3ab902d2-35a8-4cef-da36-a7939702ef77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the max length is: 501\n",
            "review example: so what they are great job  u back to bar or may decide to be seated next grooming until 2pm  when she was either  put yourself the order which is it s 2 bottles and mush as though i did nt impressed with the place is not  it soon as a very exciting at least they were nt complain \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding\n",
        "hist = {}\n",
        "for t in list(df[\"Text\"].values):\n",
        "    temp = t.split()\n",
        "    for word in temp:\n",
        "        hist[word] = hist.get(word, 0) + 1\n",
        "        pass\n",
        "    pass\n",
        "\n",
        "ind = 1\n",
        "word2ind, ind2word = {}, {}\n",
        "\n",
        "for k, v in sorted(hist.items(), key=lambda x: x[1], reverse=True):\n",
        "    word2ind[k] = ind\n",
        "    ind2word[ind] = k\n",
        "    ind += 1\n",
        "    pass\n",
        "\n",
        "\n",
        "def encoder(df):\n",
        "    X = []\n",
        "    for t in list(df[\"Text\"].values):\n",
        "        temp = []\n",
        "        words = t.split()\n",
        "        for word in words:\n",
        "            temp.append(word2ind[word])\n",
        "            pass\n",
        "        X.append(temp)\n",
        "        pass\n",
        "    return X"
      ],
      "metadata": {
        "id": "D6-AFpgeGX_j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, test, validation split\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=66)\n",
        "\n",
        "print(\"train shape is: {}\".format(train.shape))\n",
        "print(\"test shape is: {}\".format(test.shape))\n",
        "print(\n",
        "    \"The train set contains {:.2f}% positive reviews\".format(train[\"st\"].mean() * 100)\n",
        ")\n",
        "print(\"The test set cintains {:.2f}% positive reviews\".format(test[\"st\"].mean() * 100))\n",
        "\n",
        "train, validation = train_test_split(train, test_size=0.2, random_state=66)\n",
        "\n",
        "# get X for every dataset\n",
        "X_train = encoder(train)\n",
        "X_val = encoder(validation)\n",
        "X_test = encoder(test)\n",
        "\n",
        "# padding and truncate\n",
        "def padding_trun(max_feature, X):\n",
        "    new_X = np.zeros((len(X), max_feature), dtype=int)\n",
        "    for i, x in enumerate(X):\n",
        "        if len(x) > max_feature:\n",
        "            new_X[i, :] = np.array(x[:max_feature], dtype=int)\n",
        "        elif len(x) < max_feature:\n",
        "            temp = copy.deepcopy(x)\n",
        "            while len(temp) != max_feature:\n",
        "                temp.insert(0, 0)\n",
        "                pass\n",
        "            new_X[i, :] = np.array(temp, dtype=int)\n",
        "        else:\n",
        "            new_X[i, :] = np.array(x, dtype=int)\n",
        "        pass\n",
        "    return new_X\n",
        "\n",
        "\n",
        "max_feature = 256\n",
        "X_train = padding_trun(max_feature, X_train)\n",
        "y_train = np.array(train[\"st\"].values, dtype=int)\n",
        "\n",
        "X_test = padding_trun(max_feature, X_test)\n",
        "y_test = np.array(test[\"st\"].values, dtype=int)\n",
        "\n",
        "X_val = padding_trun(max_feature, X_val)\n",
        "y_val = np.array(validation[\"st\"].values, dtype=int)\n",
        "\n",
        "\n",
        "# convert to tensor\n",
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "# build dataloaders\n",
        "batch_size = 50\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size, drop_last=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhB1YpBoGls6",
        "outputId": "8c1cfc85-5ff8-4692-a986-0e8cf9307db9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape is: (8000, 2)\n",
            "test shape is: (2000, 2)\n",
            "The train set contains 50.09% positive reviews\n",
            "The test set cintains 49.65% positive reviews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        word_voc_count,\n",
        "        output_size,\n",
        "        embedding_dim,\n",
        "        hidden_dim,\n",
        "        layer_num,\n",
        "        drop_prob,\n",
        "    ):\n",
        "    # inputs -> embedding layer -> LSTM -> fully connected layer -> sigmoid -> predictions\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_num = layer_num\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # embedding layer\n",
        "        self.embedding = nn.Embedding(word_voc_count, embedding_dim)\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim, layer_num, dropout=drop_prob, batch_first=True\n",
        "        )\n",
        "\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        # fully connected layer using linear function\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "        # sigmoid activation function\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        # For prediction\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        sigmoid_out = self.sigmoid(out)\n",
        "\n",
        "        sigmoid_out = sigmoid_out.view(batch_size, -1)\n",
        "        sigmoid_out = sigmoid_out[:, -1]\n",
        "\n",
        "        return sigmoid_out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        if device_gpu:\n",
        "            hidden = (\n",
        "                weight.new(self.layer_num, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                weight.new(self.layer_num, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "            )\n",
        "        else:\n",
        "            hidden = (\n",
        "                weight.new(self.layer_num, batch_size, self.hidden_dim).zero_(),\n",
        "                weight.new(self.layer_num, batch_size, self.hidden_dim).zero_(),\n",
        "            )\n",
        "\n",
        "        return hidden\n",
        "\n",
        "\n",
        "word_voc_count = len(word2ind) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 512\n",
        "hidden_dim = 256\n",
        "layer_num = 2\n",
        "drop_prob = 0.35\n",
        "model = LSTM(word_voc_count, output_size, embedding_dim, hidden_dim, layer_num, drop_prob)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD5kFZmPG6hE",
        "outputId": "f908a889-744b-4bad-a69f-3f227cde56d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (embedding): Embedding(39678, 512)\n",
            "  (lstm): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.35)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimization functions\n",
        "# GPU\n",
        "device_gpu = True\n",
        "learning_rate = 0.001\n",
        "\n",
        "# binary cross entropy for the binary classification problems\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# achieves acc of 82% which outperforms SGD with acc of 75%\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "count = 0\n",
        "print_epoch = 100\n",
        "clip = 5\n",
        "\n",
        "if device_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "model.train()\n",
        "for e in range(epochs):\n",
        "    hid = model.init_hidden(batch_size)\n",
        "\n",
        "    for predictors, lab_y in train_loader:\n",
        "        count += 1\n",
        "\n",
        "        if device_gpu:\n",
        "            predictors, lab_y = predictors.cuda(), lab_y.cuda()\n",
        "\n",
        "        hid = tuple([each.data for each in hid])\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        predictors = predictors.type(torch.LongTensor)\n",
        "        output, hid = model(predictors.cuda(), hid)\n",
        "\n",
        "        loss = criterion(output.squeeze(), lab_y.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        if count % print_epoch == 0:\n",
        "            val_hid = model.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            model.eval()\n",
        "            for predictors, lab_y in valid_loader:\n",
        "                val_hid = tuple([each.data for each in val_hid])\n",
        "\n",
        "                if device_gpu:\n",
        "                    predictors, lab_y = predictors.cuda(), lab_y.cuda()\n",
        "\n",
        "                predictors = predictors.type(torch.LongTensor)\n",
        "\n",
        "                if (predictors.shape[0], predictors.shape[1]) != (batch_size, max_feature):\n",
        "                    continue\n",
        "\n",
        "                output, val_hid = model(predictors.cuda(), val_hid)\n",
        "                val_loss = criterion(output.squeeze(), lab_y.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            model.train()\n",
        "            print(\n",
        "                \"Epochs: {}, \".format(e + 1),\n",
        "                \"Steps: {}, \".format(count),\n",
        "                \"Loss: {:.6f}, \".format(loss.item()),\n",
        "            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61ZIUCPlHGw_",
        "outputId": "f1428397-e056-4487-8f28-63b6f62974a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1,  Steps: 100,  Loss: 0.629395, \n",
            "Epochs: 2,  Steps: 200,  Loss: 0.332007, \n",
            "Epochs: 3,  Steps: 300,  Loss: 0.188847, \n",
            "Epochs: 4,  Steps: 400,  Loss: 0.154898, \n",
            "Epochs: 4,  Steps: 500,  Loss: 0.104656, \n",
            "Epochs: 5,  Steps: 600,  Loss: 0.058398, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_testing = list()\n",
        "correct_count = 0\n",
        "hid = model.init_hidden(batch_size)\n",
        "\n",
        "res = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for predictors, lab_y in test_loader:\n",
        "\n",
        "    hid = tuple([each.data for each in hid])\n",
        "\n",
        "    if device_gpu:\n",
        "        predictors, lab_y = predictors.cuda(), lab_y.cuda()\n",
        "\n",
        "    predictors = predictors.type(torch.LongTensor)\n",
        "    output, hid = model(predictors.cuda(), hid)\n",
        "\n",
        "    test_loss = criterion(output.squeeze(), lab_y.float())\n",
        "    loss_testing.append(test_loss.item())\n",
        "\n",
        "    pred = torch.round(output.squeeze())\n",
        "\n",
        "    correct_tensor = pred.eq(lab_y.float().view_as(pred))\n",
        "\n",
        "    if device_gpu:\n",
        "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    else:\n",
        "        correct = np.squeeze(correct_tensor.numpy())\n",
        "\n",
        "    res += list(correct)\n",
        "    correct_count += np.sum(correct)\n",
        "    \n",
        "acc_testing = correct_count / len(test_loader.dataset)\n",
        "\n",
        "print(\"Loss for the test dataset:\", np.mean(loss_testing))\n",
        "print(\"Accuracy for the test dataset:\", acc_testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve_4ypDSHPjA",
        "outputId": "d462c005-2d7e-4832-d86b-5ca7397c00e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss for the test dataset: 0.4390813861042261\n",
            "Accuracy for the test dataset: 0.8685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output file for cases analysis\n",
        "test[\"res\"] = res\n",
        "test.to_csv('/content/drive/My Drive/testdata_syn.csv')"
      ],
      "metadata": {
        "id": "p73Pf3AnPjMk"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}